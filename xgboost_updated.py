# -*- coding: utf-8 -*-
"""XGBoost-updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14CDT-F1tmdBJsySNN62wDvu55RUS3-er
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from seaborn import heatmap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from seaborn import heatmap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor

#from nt import *
#import ntpath as path

#!pip install xgboost

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import xlrd 
import openpyxl
#data = pd.read_excel(io='KAYISI4.xlsx',header = 0)

#plt.style.use('ggplot')

dataset = pd.read_csv("KAYISI3.csv", sep=';' , index_col=0  )
dataset= dataset.drop(["AY","YIL"], axis=1)

from google.colab import drive
drive.mount('/content/drive')

dataset



dataset = dataset[0:]
print(dataset)

corr= dataset.corr()
corr

dataset = dataset.replace(np.nan, 0)

type(dataset.index[0])

dataset.index = pd.to_datetime(dataset.index, format='%d.%m.%Y')

dataset.head

plt.plot(dataset.index.values, dataset.IHRACAT_MIKTAR1)

X = dataset["IHRACAT_MIKTAR1"]
y = dataset["IHRACAT_MIKTAR1"]

X_train = X[0:215]
X_test = X[215:]
y_train = y[1:216]
y_test = y[216:]

X_train = pd.DataFrame(X_train, columns=dataset.columns)
X_test = pd.DataFrame(X_test, columns=dataset.columns)
y_train = pd.DataFrame(y_train, columns=dataset.columns)
y_test = pd.DataFrame(y_test, columns=dataset.columns)

y_test

scaler = MinMaxScaler(feature_range=(0.1, 0.9))
X_scaled_train = scaler.fit_transform(X_train.values)
X_scaled_test = scaler.fit_transform(X_test.values)
y_scaled_train = scaler.fit_transform(y_train.values)
y_scaled_test = scaler.fit_transform(y_test.values)

X_scaled_train = pd.DataFrame(X_scaled_train, columns=dataset.columns)
X_scaled_test = pd.DataFrame(X_scaled_test, columns=dataset.columns)
y_scaled_train = pd.DataFrame(y_scaled_train, columns=dataset.columns)
y_scaled_test = pd.DataFrame(y_scaled_test, columns=dataset.columns)

X_scaled_train

X_scaled_train.index = X_train.index
X_scaled_test.index = X_test.index
y_scaled_train.index = y_train.index
y_scaled_test.index = y_test.index

X_scaled_train

import xgboost as xgb

DM_train = xgb.DMatrix(data = X_scaled_train, label = y_scaled_train)
DM_test = xgb.DMatrix(data = X_scaled_test, label = y_scaled_test)

from xgboost import XGBRegressor

xgb_model = XGBRegressor().fit(X_scaled_train,y_scaled_train)

y_pred = xgb_model.predict(X_test)

xgb_model

xgb_grid = {
    'colsample_bytree':[0.1, 0.2, 0.3, 0.5, 0.05],
    'n_estimators':[100, 200, 50, 80],
    'max_depth': [2,3,4,5,6],
    'learning_rate':[0.1, 0.01, 0.5]
}

import numpy as np
import pandas as pd 
from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import scale 
from sklearn import model_selection
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import BaggingRegressor

xgb = XGBRegressor()

xgb_cv = GridSearchCV(xgb,
                      param_grid = xgb_grid,
                      cv = 10,
                      scoring='neg_mean_squared_error',
                      n_jobs = -1,
                     verbose=2)

xgb_cv.fit(X_scaled_train,y_scaled_train)

xgb_cv.best_params_

xgb_cv.best_score_

#grafik için yeni eklenen
means = xgb_cv.cv_results_['mean_test_score']
stds = xgb_cv.cv_results_['std_test_score']
params = xgb_cv.cv_results_['params']

#grafik için yeni eklenen
d =pd.DataFrame(params)
d['Mean'] = means
d['Std Dev'] = stds

#grafik için yeni eklenen
d.to_excel("gridsearch_sumeyye.xlsx")

import seaborn as sns

#grafik için yeni eklenen
param_ = ['colsample_bytree',	'learning_rate', 'max_depth', 'n_estimators']
fig, ax = plt.subplots(2, 2, figsize=(10,6), squeeze=False)
ax = ax.ravel()
for i in range(4):
    ax[i].set_title('Distribution of mean accuracy with {}'.format(param_[i]))
    sns.violinplot(x=param_[i],y='Mean',data=d,ax=ax[i])
fig.tight_layout(pad=1.5)
plt.show()
sns.catplot(x='colsample_bytree', y='Mean', hue='learning_rate', kind="swarm", data=d)
plt.show()

xgb_tuned = XGBRegressor(colsample_bytree = 0.1,
            n_estimators = 50,
            max_depth = 2,
            learning_rate=0.1)

xgb_tuned = xgb_tuned.fit(X_train,y_train)

y_pred = xgb_tuned.predict(y_test)
np.sqrt(mean_squared_error(y_test,y_pred))

y_pred

y_pred = pd.DataFrame(y_pred, columns=y_test.columns)

y_pred.index = y_test.index

y_pred

y_test

import numpy as np
def mape(actual,pred):
    return np.mean(np.abs((actual - pred) / actual)) * 100
result = mape(y_test,y_pred)
print("The mean absolute percentage error (MAPE): ",result)

import numpy as np
def rmse(predictions, targets):
    return np.sqrt(((predictions - targets) ** 2).mean())
result = rmse(y_test,y_pred)
print("RMSE: ",result)

pip install sklearn

from sklearn.metrics import r2_score
r2 = r2_score(y_test,y_pred)
print('r2 score for perfect model is', r2)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print('Mean Absolute Error (MAE): %.2f' % mae)
print('Mean Squared Error (MSE): %.2f' % mse)
print('Root Mean Squared Error (RMSE): %.2f' % rmse)



plt.figure(figsize=(12, 5))
plt.xlabel("Year-Month")
plt.ylabel("Predicted & Actual Values")
plt.title("XGBOOST")
plt.plot(y_test, color ="red")
plt.plot(y_pred, color ='blue')
plt.show()