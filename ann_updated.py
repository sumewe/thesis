# -*- coding: utf-8 -*-
"""ANN-updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yj3I3cOTxR2DCdGvY1pWdo5r8qp4YwlV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from seaborn import heatmap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from seaborn import heatmap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor

# from nt import *
# import ntpath as path

plt.style.use('ggplot')

dataset = pd.read_csv("KAYISI3.csv", sep=';' , index_col=0  )
dataset= dataset.drop(["AY","YIL"], axis=1)

dataset

dataset = dataset[0:]
print(dataset)

corr= dataset.corr()
corr

dataset = dataset.replace(np.nan, 0)

type(dataset.index[0])

dataset.index = pd.to_datetime(dataset.index, format='%d.%m.%Y')

dataset.head

plt.plot(dataset.index.values, dataset.IHRACAT_MIKTAR1)

dataset.describe()

dataset

X = dataset["IHRACAT_MIKTAR1"]
y = dataset["IHRACAT_MIKTAR1"]

X_train = X[0:215]
X_test = X[215:]
y_train = y[1:216]
y_test = y[216:]

X_train = pd.DataFrame(X_train, columns=dataset.columns)
X_test = pd.DataFrame(X_test, columns=dataset.columns)
y_train = pd.DataFrame(y_train, columns=dataset.columns)
y_test = pd.DataFrame(y_test, columns=dataset.columns)

y_test

scaler = MinMaxScaler(feature_range=(0.1, 0.9))
X_scaled_train = scaler.fit_transform(X_train.values)
X_scaled_test = scaler.fit_transform(X_test.values)
y_scaled_train = scaler.fit_transform(y_train.values)
y_scaled_test = scaler.fit_transform(y_test.values)

X_scaled_train = pd.DataFrame(X_scaled_train, columns=dataset.columns)
X_scaled_test = pd.DataFrame(X_scaled_test, columns=dataset.columns)
y_scaled_train = pd.DataFrame(y_scaled_train, columns=dataset.columns)
y_scaled_test = pd.DataFrame(y_scaled_test, columns=dataset.columns)

X_scaled_train

X_scaled_train.index = X_train.index
X_scaled_test.index = X_test.index
y_scaled_train.index = y_train.index
y_scaled_test.index = y_test.index

X_scaled_train

mlp_model = MLPRegressor().fit(X_scaled_train, y_scaled_train)

mlp_model

mlp_model = MLPRegressor(hidden_layer_sizes = (100,20)).fit(X_scaled_train, y_scaled_train)

mlp_model

mlp_model.n_layers_

y_pred = mlp_model.predict(X_test)

"""np.sqrt(mean_squared_error(y_test, y_pred))"""

y_pred

y_test

# import numpy as np
# import pandas as pd 
from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score
# from sklearn.metrics import mean_squared_error, r2_score
# import matplotlib.pyplot as plt
# from sklearn.preprocessing import scale 
# from sklearn import model_selection
# from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
# from sklearn.neighbors import KNeighborsRegressor
# from sklearn.ensemble import BaggingRegressor

from warnings import filterwarnings
filterwarnings('ignore')

mlp_params = {'alpha': [0.1, 0.01,0.005],
             'hidden_layer_sizes': [(20,20,20),(100,50,150),(300,200,150)],
             'activation': ['relu','logistic']}

mlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv = 10, scoring='neg_mean_squared_error', n_jobs=-1,verbose=2)

fitted_model = mlp_cv_model.fit(X_scaled_train, y_scaled_train)
pred_grid = fitted_model.predict(X_scaled_test)

mlp_cv_model.best_params_

mlp_cv_model.best_score_

#grafik için yeni eklenen
means = mlp_cv_model.cv_results_['mean_test_score']
stds = mlp_cv_model.cv_results_['std_test_score']
params = mlp_cv_model.cv_results_['params']

#grafik için yeni eklenen
d =pd.DataFrame(params)
d['Mean'] = means
d['Std Dev'] = stds

#grafik için yeni eklenen
d.to_excel("gridsearch_sumeyye.xlsx")

import seaborn as sns

#grafik için yeni eklenen
param_ = ['activation',	'alpha', 'hidden_layer_sizes']
fig, ax = plt.subplots(3, 1, figsize=(5,8), squeeze=False)
ax = ax.ravel()
for i in range(3):
    ax[i].set_title('Distribution of mean accuracy with {}'.format(param_[i]))
    sns.violinplot(x=param_[i],y='Mean',data=d,ax=ax[i])
fig.tight_layout(pad=1.5)
plt.show()
sns.catplot(x='activation', y='Mean', hue='alpha', kind="swarm", data=d)
plt.show()

mlp_tuned = MLPRegressor(alpha = 0.1, hidden_layer_sizes = (100, 50, 150),activation='relu')

mlp_tuned.fit(X_train, y_train)

y_pred = mlp_tuned.predict(y_test)

y_pred = pd.DataFrame(y_pred, columns=y_test.columns)
y_pred.index = y_test.index

y_pred

y_test



"""np.sqrt(mean_squared_error(y_test, y_pred))

mean_squared_error(y_test, y_pred)
"""



"""rmse = np.sqrt((y_pred - y_test) ** 2).mean()
print('The Roor Mean Squared Error of our forecasts is {}'.format(round(rmse, 2 )))

"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print('Mean Absolute Error (MAE): %.2f' % mae)
print('Mean Squared Error (MSE): %.2f' % mse)
print('Root Mean Squared Error (RMSE): %.2f' % rmse)

from sklearn.metrics import r2_score
r2 = r2_score(y_test,y_pred)
print('r2 score for perfect model is', r2)

import numpy as np
def mape(actual,pred):
    return np.mean(np.abs((actual - pred) / actual)) * 100
result = mape(y_test,y_pred)
print("The mean absolute percentage error (MAPE): ",result)

y_test

y_pred

plt.figure(figsize=(12, 5))
plt.xlabel("Year-Month")
plt.ylabel("Predicted & Actual Values")
plt.title("MLPRegressor")
plt.plot(y_test,linewidth=2, color ="red")
plt.plot(y_pred, color ='blue')
plt.show()